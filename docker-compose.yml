version: "3.9"

x-robotoff-base-volumes:
  &robotoff-base-volumes
  - ./data:/opt/robotoff/data
  - ./datasets:/opt/robotoff/datasets
  - ./tf_models:/opt/robotoff/tf_models
  - ./models:/opt/robotoff/models

x-robotoff-base:
  &robotoff-base
  restart: $RESTART_POLICY
  image: ghcr.io/openfoodfacts/robotoff:${TAG}
  volumes: *robotoff-base-volumes

x-robotoff-base-env:
  &robotoff-base-env
  LOG_LEVEL:
  ROBOTOFF_INSTANCE:
  ROBOTOFF_TLD:
  ROBOTOFF_SCHEME:
  STATIC_DOMAIN:
  GUNICORN_NUM_WORKERS:
  ROBOTOFF_UPDATED_PRODUCT_WAIT:
  REDIS_HOST:
  POSTGRES_HOST:
  POSTGRES_DB:
  POSTGRES_USER:
  POSTGRES_PASSWORD:
  MONGO_URI:
  OFF_USER:
  OFF_PASSWORD:
  INFLUXDB_HOST:
  INFLUXDB_PORT:
  INFLUXDB_BUCKET:
  INFLUXDB_AUTH_TOKEN:
  SLACK_TOKEN:
  SENTRY_DSN:
  ELASTIC_HOST:
  ELASTIC_PASSWORD:
  ELASTIC_USER:
  TRITON_HOST:
  ENABLE_MONGODB_ACCESS:
  IN_DOCKER_CONTAINER:
  NUM_RQ_WORKERS: 4 # Update worker service command accordingly if you change this settings

x-robotoff-worker-base:
  &robotoff-worker
  restart: $RESTART_POLICY
  image: ghcr.io/openfoodfacts/robotoff:${TAG}
  volumes: *robotoff-base-volumes
  environment: *robotoff-base-env
  depends_on:
    - postgres
  mem_limit: 8g
services:
  api:
    <<: *robotoff-base
    environment: *robotoff-base-env
    mem_limit: 4g
    ports:
      - "${ROBOTOFF_EXPOSE:-5500}:5500"
    depends_on:
      - postgres

  worker_high_1:
    <<: *robotoff-worker
    container_name: ${COMPOSE_PROJECT_NAME:-robotoff}_worker_high_1
    command: python -m robotoff run-worker robotoff-high-1

  worker_high_2:
    <<: *robotoff-worker
    container_name: ${COMPOSE_PROJECT_NAME:-robotoff}_worker_high_2
    command: python -m robotoff run-worker robotoff-high-2

  worker_low_1:
    <<: *robotoff-worker
    container_name: ${COMPOSE_PROJECT_NAME:-robotoff}_worker_low_1
    # Each worker (whether it's a high or low priority worker) listens to a
    # single high priority queue
    command: python -m robotoff run-worker robotoff-high-3 robotoff-low

  worker_low_2:
    <<: *robotoff-worker
    container_name: ${COMPOSE_PROJECT_NAME:-robotoff}_worker_low_2
    command: python -m robotoff run-worker robotoff-high-4 robotoff-low

  scheduler:
    <<: *robotoff-base
    environment: *robotoff-base-env
    command: python -m robotoff run-scheduler
    mem_limit: 4g

  postgres:
    restart: $RESTART_POLICY
    image: postgres:11.2-alpine
    environment:
      - POSTGRES_USER
      - POSTGRES_PASSWORD
      - POSTGRES_DB
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - backup:/opt/robotoff-backups
      - ./scripts/backup_postgres.sh:/opt/backup_postgres.sh
    command: postgres -c shared_buffers=1024MB -c work_mem=64MB
    mem_limit: 4g
    shm_size: 1g
    ports:
      - "${POSTGRES_EXPOSE:-127.0.0.1:5432}:5432"

  redis:
    restart: $RESTART_POLICY
    image: redis:7.0.5-alpine
    volumes:
      - redis-data:/data
    environment:
      REDIS_ARGS: --save 60 1000 --appendonly yes
    mem_limit: 4g
    ports:
      - "${REDIS_EXPOSE:-127.0.0.1:6379}:6379"

  elasticsearch:
    restart: $RESTART_POLICY
    image: elasticsearch:8.5.3
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - ELASTIC_PASSWORD
      - xpack.security.http.ssl.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 262144
        hard: 262144
    mem_limit: 15g
    volumes:
      - es-data:/usr/share/elasticsearch/data

volumes:
  postgres-data:
  backup:
    name: ${COMPOSE_PROJECT_NAME:-robotoff}_backup
  es-data:
    name: ${COMPOSE_PROJECT_NAME:-robotoff}_es-data
  redis-data:
    name: ${COMPOSE_PROJECT_NAME:-robotoff}_redis-data

networks:
  default:
